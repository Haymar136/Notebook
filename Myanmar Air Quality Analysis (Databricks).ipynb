{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbba48da-737e-4990-9d17-ab8b57fc69b8",
     "showTitle": false,
     "title": ""
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Import required functions\n",
    "\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.sql.functions import col, when, to_timestamp, date_format, year, month, dayofmonth, lit\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Myanmar Air Quality Data Processing\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a5f2f01-6550-4331-81d8-de57b41c9194",
     "showTitle": false,
     "title": ""
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+---------------+----+-------+------------+-----+-----+-----+-------------+----------+------+---------+----------------+----------+-----------------+\n|  City|           Center|           Date|Year|  Month|      Season|PM1_0|PM2_5| PM10|Temperature_F|Humidity_%|   AQI|New_cases|Cumulative_cases|New_deaths|Cumulative_deaths|\n+------+-----------------+---------------+----+-------+------------+-----+-----+-----+-------------+----------+------+---------+----------------+----------+-----------------+\n|Yangon|7 Miles Mayangone|10/20/2019 0:00|2019|October|Rainy Season| 29.6|44.27|52.87|        95.67|     49.64|122.59|        0|               0|         0|                0|\n|Yangon|7 Miles Mayangone|10/21/2019 0:00|2019|October|Rainy Season|25.22|37.49|45.21|        94.42|     51.67| 105.9|        0|               0|         0|                0|\n|Yangon|7 Miles Mayangone|10/22/2019 0:00|2019|October|Rainy Season|24.46|35.84|42.32|         95.4|     49.26|101.84|        0|               0|         0|                0|\n|Yangon|7 Miles Mayangone|10/23/2019 0:00|2019|October|Rainy Season|23.42|34.53|41.37|        96.39|     48.06| 98.17|        0|               0|         0|                0|\n|Yangon|7 Miles Mayangone|10/24/2019 0:00|2019|October|Rainy Season|38.29|56.55|68.59|         93.7|     57.11|151.54|        0|               0|         0|                0|\n+------+-----------------+---------------+----+-------+------------+-----+-----+-----+-------------+----------+------+---------+----------------+----------+-----------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Load CSV data\n",
    "\n",
    "input_path = \"/FileStore/tables/myanmar-air-quality/FinalData.csv\"\n",
    "df = spark.read.csv(input_path, header=True, inferSchema=True)\n",
    "\n",
    "# Show the loaded data\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db159071-1d91-4e31-ad5e-cc65609cb126",
     "showTitle": false,
     "title": ""
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+---------------+----+-------+------------+-----+-----+-----+-------------+----------+------+---------+----------------+----------+-----------------+\n|  City|           Center|           Date|Year|  Month|      Season|PM1_0|PM2_5| PM10|Temperature_F|Humidity_%|   AQI|New_cases|Cumulative_cases|New_deaths|Cumulative_deaths|\n+------+-----------------+---------------+----+-------+------------+-----+-----+-----+-------------+----------+------+---------+----------------+----------+-----------------+\n|Yangon|7 Miles Mayangone|10/20/2019 0:00|2019|October|Rainy Season| 29.6|44.27|52.87|        95.67|     49.64|122.59|        0|               0|         0|                0|\n|Yangon|7 Miles Mayangone|10/21/2019 0:00|2019|October|Rainy Season|25.22|37.49|45.21|        94.42|     51.67| 105.9|        0|               0|         0|                0|\n|Yangon|7 Miles Mayangone|10/22/2019 0:00|2019|October|Rainy Season|24.46|35.84|42.32|         95.4|     49.26|101.84|        0|               0|         0|                0|\n|Yangon|7 Miles Mayangone|10/23/2019 0:00|2019|October|Rainy Season|23.42|34.53|41.37|        96.39|     48.06| 98.17|        0|               0|         0|                0|\n|Yangon|7 Miles Mayangone|10/24/2019 0:00|2019|October|Rainy Season|38.29|56.55|68.59|         93.7|     57.11|151.54|        0|               0|         0|                0|\n+------+-----------------+---------------+----+-------+------------+-----+-----+-----+-------------+----------+------+---------+----------------+----------+-----------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Get a list of column names\n",
    "columns = df.columns\n",
    "\n",
    "# Create a new list to store unique column names\n",
    "unique_columns = []\n",
    "\n",
    "# Track duplicates\n",
    "duplicates = {}\n",
    "\n",
    "# Process each column name\n",
    "for col_name in columns:\n",
    "    if col_name in unique_columns:\n",
    "        # If duplicate, append a suffix to make it unique\n",
    "        if col_name in duplicates:\n",
    "            duplicates[col_name] += 1\n",
    "        else:\n",
    "            duplicates[col_name] = 1\n",
    "        col_name = f\"{col_name}_{duplicates[col_name]}\"\n",
    "    \n",
    "    unique_columns.append(col_name)\n",
    "\n",
    "# Rename the columns\n",
    "df = df.toDF(*unique_columns)\n",
    "\n",
    "# Show the DataFrame with unique column names\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "902d3685-f060-4316-a574-385f45a1c8ac",
     "showTitle": false,
     "title": ""
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType, StringType, FloatType, DateType\n",
    "       \n",
    "# Convert the 'Date' column to TimestampType with the correct format\n",
    "df = df.withColumn(\"Date\", to_timestamp(col(\"Date\"), \"MM/dd/yyyy H:mm\"))\n",
    "\n",
    "# Extract Year_Key, Month_Key, and Day_Key\n",
    "df = df.withColumn(\"Year_Key\", year(col(\"Date\")).cast(StringType())) \\\n",
    "       .withColumn(\"Month_Key\", date_format(col(\"Date\"), \"yyyyMM\")) \\\n",
    "       .withColumn(\"Day_Key\", date_format(col(\"Date\"), \"yyyyMMdd\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a25d343-654f-495d-bc52-a46801dc5701",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate Health_Impact based on PM2_5 value\n",
    "# Adjust the classification of PM2_5 values\n",
    "df = df.withColumn(\"PM2_5_Range\", \n",
    "                   when((col(\"PM2_5\") >= 0) & (col(\"PM2_5\") <= 50), \"0-50\")\n",
    "                   .when((col(\"PM2_5\") > 50) & (col(\"PM2_5\") <= 100), \"51-100\")\n",
    "                   .when((col(\"PM2_5\") > 100) & (col(\"PM2_5\") <= 200), \"101-200\")\n",
    "                   .when((col(\"PM2_5\") > 200) & (col(\"PM2_5\") <= 300), \"201-300\")\n",
    "                   .when((col(\"PM2_5\") > 300) & (col(\"PM2_5\") <= 400), \"301-400\")\n",
    "                   .when((col(\"PM2_5\") > 400) & (col(\"PM2_5\") <= 500), \"401-500\")\n",
    "                   .otherwise(\"Unknown\")) \\\n",
    "         .withColumn(\"health_impact\", \n",
    "                    when(col(\"PM2_5_Range\") == \"0-50\", \"Good\")\n",
    "                    .when(col(\"PM2_5_Range\") == \"51-100\", \"Satisfactory\")\n",
    "                    .when(col(\"PM2_5_Range\") == \"101-200\", \"Moderate\")\n",
    "                    .when(col(\"PM2_5_Range\") == \"201-300\", \"Poor\")\n",
    "                    .when(col(\"PM2_5_Range\") == \"301-400\", \"Very poor\")\n",
    "                    .when(col(\"PM2_5_Range\") == \"401-500\", \"Severe\")\n",
    "                    .otherwise(\"Unknown\")) \\\n",
    "         .withColumn(\"Description\", \n",
    "                    when(col(\"PM2_5_Range\") == \"0-50\", \"minimal impact\")\n",
    "                    .when(col(\"PM2_5_Range\") == \"51-100\", \"minor breathing discomfort for sensitive people\")\n",
    "                    .when(col(\"PM2_5_Range\") == \"101-200\", \"breathing discomfort for people with asthma, heart disease, or lungs\")\n",
    "                    .when(col(\"PM2_5_Range\") == \"201-300\", \"breathing discomfort for most people on prolonged exposure\")\n",
    "                    .when(col(\"PM2_5_Range\") == \"301-400\", \"respiratory illness on prolonged exposure\")\n",
    "                    .when(col(\"PM2_5_Range\") == \"401-500\", \"severe respiratory illness on prolonged exposure\")\n",
    "                    .otherwise(\"Unknown\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84104e25-fa5f-45fe-a9c4-001543f2acad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop duplicate rows based on input columns\n",
    "df = df.dropDuplicates([\"City\",\"Center\", \"Date\",\"Year\",\"Month\", \"Season\",\"PM1_0\", \"PM2_5\", \"PM10\", \"Temperature_F\", \"Humidity_%\", \"AQI\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a35f81b4-14eb-4c00-bed5-ac72790af26c",
     "showTitle": false,
     "title": ""
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-------------------+--------+---------+--------+----------+-----+-----+----+-------------+----------+---+-------------+\n|  City|              Center|               Date|Year_Key|Month_Key| Day_Key|    Season|PM1_0|PM2_5|PM10|Temperature_F|Humidity_%|AQI|Health_Impact|\n+------+--------------------+-------------------+--------+---------+--------+----------+-----+-----+----+-------------+----------+---+-------------+\n|Yangon|         WWF-Myanmar|2020-04-10 00:00:00|    2020|   202004|20200410|Hot Season|  0.0|  0.0|0.58|         74.0|      26.5|0.0|         Good|\n|Yangon|Thin Gan Gyun Yan...|2020-04-25 00:00:00|    2020|   202004|20200425|Hot Season|  0.0|  0.0| 0.0|        99.15|     39.62|0.0|         Good|\n|Yangon|Thin Gan Gyun Yan...|2020-04-24 00:00:00|    2020|   202004|20200424|Hot Season|  0.0|  0.0| 0.0|        98.73|     42.01|0.0|         Good|\n|Yangon|Thin Gan Gyun Yan...|2020-04-22 00:00:00|    2020|   202004|20200422|Hot Season|  0.0|  0.0| 0.0|        98.64|      42.4|0.0|         Good|\n|Yangon|Thin Gan Gyun Yan...|2020-04-19 00:00:00|    2020|   202004|20200419|Hot Season|  0.0|  0.0| 0.0|        97.39|     42.43|0.0|         Good|\n|Yangon|Thin Gan Gyun Yan...|2020-04-18 00:00:00|    2020|   202004|20200418|Hot Season|  0.0|  0.0| 0.0|        97.18|     42.76|0.0|         Good|\n|Yangon|Thin Gan Gyun Yan...|2020-04-26 00:00:00|    2020|   202004|20200426|Hot Season|  0.0|  0.0| 0.0|        98.97|     42.78|0.0|         Good|\n|Yangon|Thin Gan Gyun Yan...|2020-04-21 00:00:00|    2020|   202004|20200421|Hot Season|  0.0|  0.0| 0.0|        98.12|     42.87|0.0|         Good|\n|Yangon|Pun Hlaing Dulwic...|2020-04-25 00:00:00|    2020|   202004|20200425|Hot Season|  0.0|  0.0| 0.0|        98.09|     42.98|0.0|         Good|\n|Yangon|Thin Gan Gyun Yan...|2020-04-23 00:00:00|    2020|   202004|20200423|Hot Season|  0.0|  0.0| 0.0|        98.83|      43.0|0.0|         Good|\n+------+--------------------+-------------------+--------+---------+--------+----------+-----+-----+----+-------------+----------+---+-------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Select and reorder columns according to the assignment output fields\n",
    "output_df = df.select(\n",
    "    col(\"City\"),\n",
    "    col(\"Center\"),\n",
    "    col(\"Date\"),\n",
    "    col(\"Year_Key\"),\n",
    "    col(\"Month_Key\"),\n",
    "    col(\"Day_Key\"),\n",
    "    col(\"Season\"),\n",
    "    col(\"PM1_0\"),\n",
    "    col(\"PM2_5\"),\n",
    "    col(\"PM10\"),\n",
    "    col(\"Temperature_F\"),\n",
    "    col(\"Humidity_%\"),\n",
    "    col(\"AQI\"),\n",
    "    col(\"Health_Impact\")\n",
    ")\n",
    "\n",
    "# Show the DataFrame with the correct output schema\n",
    "output_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29296a0f-9538-4802-8c46-55ff1b71cf79",
     "showTitle": false,
     "title": ""
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to /FileStore/tables/myanmar-air-quality/output_files/myanmar_air_quality_parquet\n"
     ]
    }
   ],
   "source": [
    "# Set the legacy time parser policy\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "\n",
    "# Output path for the parquet files\n",
    "output_path = \"/FileStore/tables/myanmar-air-quality/output_files/myanmar_air_quality_parquet\"\n",
    "\n",
    "# Write the DataFrame as parquet files\n",
    "output_df.write.mode(\"overwrite\").parquet(output_path)\n",
    "\n",
    "print(f\"Data successfully written to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd0750b1-8286-464d-8490-7918bc149543",
     "showTitle": false,
     "title": ""
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+--------------------------------------------------------------------+------------------+\n|PM2_5_Range|health_impact|Description                                                         |Average_PM2_5     |\n+-----------+-------------+--------------------------------------------------------------------+------------------+\n|0-50       |Good         |minimal impact                                                      |19.306436068701842|\n|101-200    |Moderate     |breathing discomfort for people with asthma, heart disease, or lungs|120.15159090909087|\n|51-100     |Satisfactory |minor breathing discomfort for sensitive people                     |67.26554631828975 |\n+-----------+-------------+--------------------------------------------------------------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Group by the PM2_5_Range and health_impact, and calculate the average PM2_5\n",
    "summary_df = df.groupBy(\"PM2_5_Range\", \"health_impact\", \"Description\").agg({\"PM2_5\": \"avg\"}).withColumnRenamed(\"avg(PM2_5)\", \"Average_PM2_5\")\n",
    "\n",
    "# Show the summary\n",
    "summary_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5856aae-f90c-4382-a101-eacfcd898244",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": null
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "USE SCHEMA air_quality;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS myanmar_air_quality;\n",
    "\n",
    "CONVERT TO DELTA myanmar_air_quality;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "454f280c-a470-49b0-b6f4-3a54be002f19",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th><th>num_skipped_corrupt_files</th></tr></thead><tbody><tr><td>5122</td><td>5122</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         5122,
         5122,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 106
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_skipped_corrupt_files",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- Step 1: Read new or updated data from the Parquet files into a staging table\n",
    "DROP TABLE IF EXISTS myanmar_air_quality_staging;\n",
    "\n",
    "CREATE TABLE myanmar_air_quality_staging;\n",
    "\n",
    "COPY INTO myanmar_air_quality_staging\n",
    "  FROM '/FileStore/tables/myanmar-air-quality/output_files/myanmar_air_quality_parquet'\n",
    "  FILEFORMAT = PARQUET\n",
    "  FORMAT_OPTIONS ('inferSchema' = 'true', 'header' = 'true')\n",
    "  COPY_OPTIONS ('mergeSchema' = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fab863c-9763-4bf6-8faf-2c88b48b863c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_updated_rows</th><th>num_deleted_rows</th><th>num_inserted_rows</th></tr></thead><tbody><tr><td>5122</td><td>5122</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         5122,
         5122,
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 108
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_updated_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_deleted_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "\n",
    "-- Step 2: Merge new/updated data into the target Delta table\n",
    "MERGE INTO myanmar_air_quality AS target\n",
    "USING myanmar_air_quality_staging AS source\n",
    "ON    target.City = source.City\n",
    "AND   target.Center = source.Center\n",
    "AND   target.Date = source.Date\n",
    "AND   target.Season = source.Season\n",
    "AND   target.PM1_0 = source.PM1_0\n",
    "AND   target.PM2_5 = source.PM2_5\n",
    "AND   target.PM10 = source.PM10\n",
    "AND   target.Temperature_F = source.Temperature_F\n",
    "AND   target.`Humidity_%` = source.`Humidity_%`\n",
    "AND   target.AQI = source.AQI\n",
    "-- Update matched rows\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET *\n",
    "-- Insert unmatched rows\n",
    "WHEN NOT MATCHED THEN\n",
    "  INSERT *;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 76005973474662,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Myanmar Air Quality Analysis",
   "widgets": {}
  },
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "93e5b3c8-5207-458a-b553-8473e8666f04",
    "default_lakehouse_name": "air_quality",
    "default_lakehouse_workspace_id": "4f24d2de-6891-4344-8e60-f1bc7077e5bb"
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default"
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
